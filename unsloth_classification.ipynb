{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqM-T1RTzY6C"
      },
      "source": [
        "# Text classification with Unsloth\n",
        "\n",
        "This modified Unsloth notebook trains an LLM on any text classification dataset, where the input is a csv with columns \"text\" and \"label\".\n",
        "\n",
        "### Added features:\n",
        "\n",
        "- Trims the classification head to contain only the number tokens such as \"1\", \"2\" etc, which saves 1 GB of VRAM, allows you to train the head without massive memory usage, and makes the start of the training session more stable.\n",
        "- Only the last token in the sequence contributes to the loss, the model doesn't waste its capacity by trying to predict the input\n",
        "- includes \"group_by_length = True\" which speeds up training significantly for unbalanced sequence lengths\n",
        "- Efficiently evaluates the accuracy on the validation set using batched inference\n",
        "\n",
        "### Update 4th of May 2025:\n",
        "\n",
        "- Added support for more than 2 classes\n",
        "- The classification head is now built back up to the original size after training, no more errors in external libraries.\n",
        "- Made the batched inference part much faster and cleaner\n",
        "- Changed model to Qwen 3\n",
        "- Improved comments to explain the complicated parts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unsloth"
      ],
      "metadata": {
        "id": "SuL98rHYNdEW",
        "outputId": "b121d903-e60c-47b4-a5d4-90ccb02c8145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.10.9-py3-none-any.whl.metadata (59 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/59.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unsloth_zoo>=2025.10.10 (from unsloth)\n",
            "  Downloading unsloth_zoo-2025.10.10-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.23.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth)\n",
            "  Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.4.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\n",
            "Collecting datasets!=4.0.*,!=4.1.0,>=3.4.1 (from unsloth)\n",
            "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (1.11.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.17.1)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.3)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.2)\n",
            "Collecting transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3 (from unsloth)\n",
            "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl!=0.19.0,<=0.23.0,>=0.18.2 (from unsloth)\n",
            "  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (3.20.0)\n",
            "Collecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth) (0.22.1)\n",
            "Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.10.10->unsloth)\n",
            "  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.10.10->unsloth)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.10.10->unsloth) (11.3.0)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.10.10->unsloth)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (3.13.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (1.22.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth) (1.3.1)\n",
            "Downloading unsloth-2025.10.9-py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m346.7/346.7 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl (60.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.23.0-py3-none-any.whl (564 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.10.10-py3-none-any.whl (270 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m270.4/270.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.35-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchao, shtab, pyarrow, msgspec, tyro, xformers, transformers, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n",
            "  Attempting uninstall: torchao\n",
            "    Found existing installation: torchao 0.10.0\n",
            "    Uninstalling torchao-0.10.0:\n",
            "      Successfully uninstalled torchao-0.10.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.1\n",
            "    Uninstalling transformers-4.57.1:\n",
            "      Successfully uninstalled transformers-4.57.1\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.48.1 cut_cross_entropy-25.1.1 datasets-4.3.0 msgspec-0.19.0 pyarrow-22.0.0 shtab-1.7.2 torchao-0.14.1 transformers-4.56.2 trl-0.23.0 tyro-0.9.35 unsloth-2025.10.9 unsloth_zoo-2025.10.10 xformers-0.0.32.post2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QVWKvn0yKgYt",
        "outputId": "d5c1cfb7-7d06-47ab-ae0f-91b18aa1ebbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao:Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu126 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "# needed as this function doesn't like it when the lm_head has its size changed\n",
        "from unsloth import tokenizer_utils\n",
        "def do_nothing(*args, **kwargs):\n",
        "    pass\n",
        "tokenizer_utils.fix_untrained_tokens = do_nothing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "\n",
        "!kaggle competitions download -c jigsaw-agile-community-rules\n",
        "!unzip \"jigsaw-agile-community-rules.zip\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "xzIZ3SprOcyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1CBH68JwKgYv",
        "outputId": "1c187c09-71e3-472f-b7b6-04ddab4cd4e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "f8336b274cc24d7fbfedaa0f841f83cd",
            "e4cbee7ae6e54774b223f83bb7e4639d",
            "4bf6ffb1559c4765ae7add3d4254c2ba",
            "9f67a2eb09e14218ac05251527f5a94e",
            "aeaa825fabdb4788ae06e0c3756e2224",
            "4fc326fbd2b348c8be49ceca07124c1e",
            "ce8d6fd57aef4ece83eaeb9b5c0ee0ab",
            "291fc04ec56d4085ab0ede398aad21b1",
            "a06430ef7ad141b48ef923a410bc0b46",
            "443eab1dba2642d79f9cf003efcb1800",
            "bbb4176350bf4325b8c84bb919913653",
            "36e8f92172fb4da1b5c39872d9967d36",
            "e03eadf2a26449c5bfb662ab22221adf",
            "382767c88dad4b93abb20406f5cb3513",
            "37cb19d891ef46409704c7ea7797d462",
            "a2135168f99845f486c5170aa6bdb3e2",
            "0efd46fac188423ba286ec292266aee3",
            "6ff963ac45be49ae82611bca330c527a",
            "f06465261f9c462ba40545effffd15ba",
            "654adb65cf0f437c822797ebd9a274c1",
            "99ebf1e4b90c498d804b7aaf293bd2c5",
            "4498d891ea774062bd9ee7dea0b09402",
            "668d76b8341d4f26af3f6c9885d00c69",
            "d110dca213704c26af707e0c085f01a9",
            "75b93b8951d34bb4b2aee3565b9331ab",
            "d65f695bc30d4d3d900ff9df152a82a6",
            "a6c90c4f3a5c43d5a6e71e7904578cc5",
            "f576539d1b9746c0bef3cd98154bc54a",
            "c82f5d962d2c46dfb275d34e81ec4bf9",
            "61a17b50f2594bf9b5689e8d19286275",
            "f3c4c3d3a2ee4c2f982dd32bf94d7164",
            "411747a1dc84446986a8603dfc3c06aa",
            "25797b68da6342cd8723270ce8ac2f92",
            "f6ae20cbd8e444cca886a0d6afc45946",
            "5a4a35c953944292b3538426f17a06a4",
            "dd83c905118d479db45e09b1e1c450da",
            "2091e36b3d6940589c23f3bab1a5ab8f",
            "1e425b546fb741deab5040881203dc3b",
            "5a82ad4e7bc648c78185c6b9c2be03fd",
            "621031dd3727413792271a2cc511616e",
            "af5f70e0458a4921a1b9b23258c9040c"
          ]
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Major: 7, Minor: 5\n",
            "==((====))==  Unsloth 2025.10.9: Fast Qwen3 patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8336b274cc24d7fbfedaa0f841f83cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36e8f92172fb4da1b5c39872d9967d36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "668d76b8341d4f26af3f6c9885d00c69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.08G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6ae20cbd8e444cca886a0d6afc45946",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a4a35c953944292b3538426f17a06a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/166 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd83c905118d479db45e09b1e1c450da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2091e36b3d6940589c23f3bab1a5ab8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e425b546fb741deab5040881203dc3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a82ad4e7bc648c78185c6b9c2be03fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "621031dd3727413792271a2cc511616e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af5f70e0458a4921a1b9b23258c9040c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "print(f\"Major: {major_version}, Minor: {minor_version}\")\n",
        "from datasets import load_dataset\n",
        "import datasets\n",
        "from trl import SFTTrainer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from typing import Tuple\n",
        "import warnings\n",
        "from typing import Any, Dict, List, Union\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NUM_CLASSES = 2 # number of classes in the csv\n",
        "\n",
        "max_seq_length = 256 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "\n",
        "model_name = \"unsloth/Qwen3-4B-Base\";load_in_4bit = False\n",
        "# model_name = \"Qwen3-4B-Base\";load_in_4bit = False\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,load_in_4bit = load_in_4bit,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now trim the classification head so the model can only say numbers 0-NUM_CLASSES and no other words. (We don't use 0 here but keeping it makes everything simpler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EZKrzwilKgYx",
        "outputId": "81b0d525-3a06-4214-efa1-e80f3e07a95e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2560])\n",
            "torch.Size([151936, 2560])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{15: 0, 16: 1, 17: 2}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "number_token_ids = []\n",
        "for i in range(0, NUM_CLASSES+1):\n",
        "    number_token_ids.append(tokenizer.encode(str(i), add_special_tokens=False)[0])\n",
        "# keep only the number tokens from lm_head\n",
        "par = torch.nn.Parameter(model.lm_head.weight[number_token_ids, :])\n",
        "\n",
        "old_shape = model.lm_head.weight.shape\n",
        "old_size = old_shape[0]\n",
        "print(par.shape)\n",
        "print(old_shape)\n",
        "\n",
        "model.lm_head.weight = par\n",
        "\n",
        "reverse_map = {value: idx for idx, value in enumerate(number_token_ids)} # will be used later to convert an idx from the old tokenizer to the new lm_head\n",
        "reverse_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tFNApMlEKgYz",
        "outputId": "d67f8a12-be07-4841-8309-a6a42815aa7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Offloading output_embeddings to disk to save VRAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.10.9 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Training lm_head in mixed precision to save VRAM\n",
            "trainable parameters: 33037824\n"
          ]
        }
      ],
      "source": [
        "from peft import LoftQConfig\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\n",
        "        \"lm_head\", # can easily be trained because it now has a small size\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = True,  # We support rank stabilized LoRA\n",
        "    # init_lora_weights = 'loftq',\n",
        "    # loftq_config = LoftQConfig(loftq_bits = 4, loftq_iter = 1), # And LoftQ\n",
        ")\n",
        "print(\"trainable parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "df = pd.read_csv(\"train.csv\") # columns are comment,rule,label\n",
        "\n",
        "print(\"--- Original DataFrame ---\")\n",
        "print(df)\n",
        "print(\"\\n\")\n",
        "\n",
        "id_vars = ['rule', 'rule_violation']\n",
        "value_vars = [\n",
        "    'body',\n",
        "    'positive_example_1',\n",
        "    'positive_example_2',\n",
        "    'negative_example_1',\n",
        "    'negative_example_2'\n",
        "]\n",
        "\n",
        "# Melt the dataframe\n",
        "long_df = df.melt(\n",
        "    id_vars=id_vars,\n",
        "    value_vars=value_vars,\n",
        "    var_name='comment_type',  # This new col tracks where the comment came from\n",
        "    value_name='comment'      # This new col holds the actual comment text\n",
        ")\n",
        "\n",
        "# 3. --- Create the 'label' column ---\n",
        "# We use np.select to create the new label based on your logic.\n",
        "\n",
        "conditions = [\n",
        "    long_df['comment_type'].str.startswith('positive'),  # Label 1 for positive examples\n",
        "    long_df['comment_type'].str.startswith('negative'),  # Label 0 for negative examples\n",
        "    long_df['comment_type'] == 'body'                    # Use 'rule_violation' for body\n",
        "]\n",
        "\n",
        "# Define the corresponding values for each condition\n",
        "choices = [\n",
        "    1,\n",
        "    0,\n",
        "    long_df['rule_violation']\n",
        "]\n",
        "\n",
        "# Apply the logic\n",
        "long_df['label'] = np.select(conditions, choices, default=-1) # default=-1 to catch errors\n",
        "long_df['label'] = long_df['label'].astype(int) # Ensure label is integer\n",
        "\n",
        "# 4. --- Create the final, clean DataFrame ---\n",
        "# We only keep the columns you requested, plus 'comment_type' for splitting.\n",
        "final_df = long_df[['comment', 'rule', 'label', 'comment_type']]\n",
        "\n",
        "print(\"--- Transformed (Long) DataFrame (intermediate) ---\")\n",
        "print(final_df.head())\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# 5. --- Create Train and Validation DataFrames ---\n",
        "\n",
        "# Validation set is all comments from the original 'body' column\n",
        "val_df = final_df[final_df['comment_type'] == 'body'].copy()\n",
        "\n",
        "# Training set is all other comments (positive/negative examples)\n",
        "train_df = final_df[final_df['comment_type'] != 'body'].copy()\n",
        "\n",
        "# 6. --- Final Cleanup ---\n",
        "# Drop the helper 'comment_type' column and reset the index\n",
        "\n",
        "train_df = train_df[['comment', 'rule', 'label']].reset_index(drop=True)\n",
        "val_df = val_df[['comment', 'rule', 'label']].reset_index(drop=True)\n",
        "\n",
        "print(\"--- Final train_df ---\")\n",
        "print(train_df)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"--- Final val_df ---\")\n",
        "print(val_df)"
      ],
      "metadata": {
        "id": "5sl4BHG3Qsgf",
        "outputId": "3ff0404f-c932-44f4-962b-b84eb6518aa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Original DataFrame ---\n",
            "      row_id                                               body  \\\n",
            "0          0  Banks don't want you to know this! Click here ...   \n",
            "1          1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
            "2          2  Lol. Try appealing the ban and say you won't d...   \n",
            "3          3  she will come your home open her legs with  an...   \n",
            "4          4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
            "...      ...                                                ...   \n",
            "2024    2024  Please edit your post so it is readable. These...   \n",
            "2025    2025  Yes, and in a right to work state they can eve...   \n",
            "2026    2026  **HD** Streams: |ENG **HD**[ Watch here..PC & ...   \n",
            "2027    2027  No. Not when doing so obviously presents a saf...   \n",
            "2028    2028  > CA is an at fault state so they will not be ...   \n",
            "\n",
            "                                                   rule      subreddit  \\\n",
            "0     No Advertising: Spam, referral links, unsolici...     Futurology   \n",
            "1     No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
            "2     No legal advice: Do not offer or request legal...   pcmasterrace   \n",
            "3     No Advertising: Spam, referral links, unsolici...            sex   \n",
            "4     No Advertising: Spam, referral links, unsolici...    hearthstone   \n",
            "...                                                 ...            ...   \n",
            "2024  No legal advice: Do not offer or request legal...  relationships   \n",
            "2025  No legal advice: Do not offer or request legal...    legaladvice   \n",
            "2026  No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
            "2027  No legal advice: Do not offer or request legal...       politics   \n",
            "2028  No legal advice: Do not offer or request legal...    legaladvice   \n",
            "\n",
            "                                     positive_example_1  \\\n",
            "0     If you could tell your younger self something ...   \n",
            "1     [I wanna kiss you all over! Stunning!](http://...   \n",
            "2     Don't break up with him or call the cops.  If ...   \n",
            "3     Selling Tyrande codes for 3â‚¬ to paypal. PM. \\n...   \n",
            "4      wow!! amazing reminds me of the old days.Well...   \n",
            "...                                                 ...   \n",
            "2024  I'm not ok with this in anyway, and think you ...   \n",
            "2025  Move as much of your assets as you can offshor...   \n",
            "2026  stitopdisca1987.tumblr.com - sex Take girl for...   \n",
            "2027  SHE ISNT A BIRTHING CHAMBER BUT EQUALLY THE BA...   \n",
            "2028  [Yes, it is. In the USA, at least](https://www...   \n",
            "\n",
            "                                     positive_example_2  \\\n",
            "0     hunt for lady for jack off in neighbourhood ht...   \n",
            "1     LOLGA.COM is One of the First Professional Onl...   \n",
            "2     It'll be dismissed: https://en.wikipedia.org/w...   \n",
            "3     tight pussy watch for your cock get her at thi...   \n",
            "4     seek for lady for sex in around http://p77.pl/...   \n",
            "...                                                 ...   \n",
            "2024  See a lawyer under the guise that you want thi...   \n",
            "2025  We have great consumer protection laws. There'...   \n",
            "2026  this girl get sex going to  to old http://mrk....   \n",
            "2027  Jail? What are you, ten years old? If they pro...   \n",
            "2028  Never pay a civil demand. \\n\\nIt's a bluff and...   \n",
            "\n",
            "                                     negative_example_1  \\\n",
            "0     Watch Golden Globe Awards 2017 Live Online in ...   \n",
            "1     #Rapper \\nğŸš¨Straight Outta Cross Keys SC ğŸš¨YouTu...   \n",
            "2     Where is there a site that still works where y...   \n",
            "3     NSFW(obviously) http://spankbang.com/iy3u/vide...   \n",
            "4     must be watch movie https://sites.google.com/s...   \n",
            "...                                                 ...   \n",
            "2024  This is just untrue.  OP is 13, not an adult -...   \n",
            "2025  LPT piratebay, transmission, vpn. Get the musi...   \n",
            "2026  NO ADS | NO ADS | NO ADS\\n\\nWe show all SOCCER...   \n",
            "2027  Who cares about that when I can keep raping in...   \n",
            "2028  Where is there a site that still works where y...   \n",
            "\n",
            "                                     negative_example_2  rule_violation  \n",
            "0     DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...               0  \n",
            "1     [15 Amazing Hidden Features Of Google Search Y...               0  \n",
            "2     Because this statement of his is true. It isn'...               1  \n",
            "3     Good News ::Download WhatsApp 2.16.230 APK for...               1  \n",
            "4     We're streaming Pokemon Veitnamese Crystal RIG...               1  \n",
            "...                                                 ...             ...  \n",
            "2024  Why should I care about all the bicyclists I i...               1  \n",
            "2025  It's not so much that I killed them, it's that...               0  \n",
            "2026  [So great! Thanks for sharing.](http://www.che...               1  \n",
            "2027  send me a private message; I may be able to he...               1  \n",
            "2028  Steal a car from an elderly person who won't n...               1  \n",
            "\n",
            "[2029 rows x 9 columns]\n",
            "\n",
            "\n",
            "--- Transformed (Long) DataFrame (intermediate) ---\n",
            "                                             comment  \\\n",
            "0  Banks don't want you to know this! Click here ...   \n",
            "1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
            "2  Lol. Try appealing the ban and say you won't d...   \n",
            "3  she will come your home open her legs with  an...   \n",
            "4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
            "\n",
            "                                                rule  label comment_type  \n",
            "0  No Advertising: Spam, referral links, unsolici...      0         body  \n",
            "1  No Advertising: Spam, referral links, unsolici...      0         body  \n",
            "2  No legal advice: Do not offer or request legal...      1         body  \n",
            "3  No Advertising: Spam, referral links, unsolici...      1         body  \n",
            "4  No Advertising: Spam, referral links, unsolici...      1         body  \n",
            "\n",
            "\n",
            "--- Final train_df ---\n",
            "                                                comment  \\\n",
            "0     If you could tell your younger self something ...   \n",
            "1     [I wanna kiss you all over! Stunning!](http://...   \n",
            "2     Don't break up with him or call the cops.  If ...   \n",
            "3     Selling Tyrande codes for 3â‚¬ to paypal. PM. \\n...   \n",
            "4      wow!! amazing reminds me of the old days.Well...   \n",
            "...                                                 ...   \n",
            "8111  Why should I care about all the bicyclists I i...   \n",
            "8112  It's not so much that I killed them, it's that...   \n",
            "8113  [So great! Thanks for sharing.](http://www.che...   \n",
            "8114  send me a private message; I may be able to he...   \n",
            "8115  Steal a car from an elderly person who won't n...   \n",
            "\n",
            "                                                   rule  label  \n",
            "0     No Advertising: Spam, referral links, unsolici...      1  \n",
            "1     No Advertising: Spam, referral links, unsolici...      1  \n",
            "2     No legal advice: Do not offer or request legal...      1  \n",
            "3     No Advertising: Spam, referral links, unsolici...      1  \n",
            "4     No Advertising: Spam, referral links, unsolici...      1  \n",
            "...                                                 ...    ...  \n",
            "8111  No legal advice: Do not offer or request legal...      0  \n",
            "8112  No legal advice: Do not offer or request legal...      0  \n",
            "8113  No Advertising: Spam, referral links, unsolici...      0  \n",
            "8114  No legal advice: Do not offer or request legal...      0  \n",
            "8115  No legal advice: Do not offer or request legal...      0  \n",
            "\n",
            "[8116 rows x 3 columns]\n",
            "\n",
            "\n",
            "--- Final val_df ---\n",
            "                                                comment  \\\n",
            "0     Banks don't want you to know this! Click here ...   \n",
            "1     SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
            "2     Lol. Try appealing the ban and say you won't d...   \n",
            "3     she will come your home open her legs with  an...   \n",
            "4     code free tyrande --->>> [Imgur](http://i.imgu...   \n",
            "...                                                 ...   \n",
            "2024  Please edit your post so it is readable. These...   \n",
            "2025  Yes, and in a right to work state they can eve...   \n",
            "2026  **HD** Streams: |ENG **HD**[ Watch here..PC & ...   \n",
            "2027  No. Not when doing so obviously presents a saf...   \n",
            "2028  > CA is an at fault state so they will not be ...   \n",
            "\n",
            "                                                   rule  label  \n",
            "0     No Advertising: Spam, referral links, unsolici...      0  \n",
            "1     No Advertising: Spam, referral links, unsolici...      0  \n",
            "2     No legal advice: Do not offer or request legal...      1  \n",
            "3     No Advertising: Spam, referral links, unsolici...      1  \n",
            "4     No Advertising: Spam, referral links, unsolici...      1  \n",
            "...                                                 ...    ...  \n",
            "2024  No legal advice: Do not offer or request legal...      1  \n",
            "2025  No legal advice: Do not offer or request legal...      0  \n",
            "2026  No Advertising: Spam, referral links, unsolici...      1  \n",
            "2027  No legal advice: Do not offer or request legal...      1  \n",
            "2028  No legal advice: Do not offer or request legal...      1  \n",
            "\n",
            "[2029 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8WhxhGYyKgY3",
        "outputId": "de10a88e-e7e4-407e-e5cc-152cb6f16140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "token_counts = [len(tokenizer.encode(x)) for x in train_df.comment]\n",
        "# plot the token counts\n",
        "a = plt.hist(token_counts, bins=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Here is a reddit comment:\n",
        "{}\n",
        "\n",
        "Classify this news into one of the following based on this rule \"{}\":\n",
        "class 0: No violation\n",
        "class 1: Violation\n",
        "\n",
        "SOLUTION\n",
        "The correct answer is: class {}\"\"\"\n",
        "\n",
        "def formatting_prompts_func(dataset_):\n",
        "    texts = []\n",
        "    for i in range(len(dataset_['comment'])):\n",
        "        text_ = dataset_['comment'].iloc[i]\n",
        "        rule_ = dataset_['rule'].iloc[i]\n",
        "        label_ = dataset_['label'].iloc[i] # the csv is setup so that the label column corresponds exactly to the 3 classes defined above in the prompt (important)\n",
        "\n",
        "        text = prompt.format(text_, rule_, label_)\n",
        "\n",
        "        texts.append(text)\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply formatting_prompts_func to train_df and val_df\n",
        "train_df['comment'] = formatting_prompts_func(train_df)\n",
        "train_df = train_df.drop(columns=[\"rule\"])\n",
        "train_df = train_df.rename(columns={\"comment\": \"text\"})\n",
        "train_dataset = datasets.Dataset.from_pandas(train_df,preserve_index=False)"
      ],
      "metadata": {
        "id": "lGLUb3MVSkhc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mReEfdXCKgY6"
      },
      "outputs": [],
      "source": [
        "# this custom collator makes it so the model trains only on the last token of the sequence. It also maps from the old tokenizer to the new lm_head indices\n",
        "class DataCollatorForLastTokenLM(DataCollatorForLanguageModeling):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *args,\n",
        "        mlm: bool = False,\n",
        "        ignore_index: int = -100,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(*args, mlm=mlm, **kwargs)\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
        "        batch = super().torch_call(examples)\n",
        "\n",
        "        for i in range(len(examples)):\n",
        "            # Find the last non-padding token\n",
        "            last_token_idx = (batch[\"labels\"][i] != self.ignore_index).nonzero()[-1].item()\n",
        "            # Set all labels to ignore_index except for the last token\n",
        "            batch[\"labels\"][i, :last_token_idx] = self.ignore_index\n",
        "            # If the last token in the text is, for example, \"2\", then this was processed with the old tokenizer into number_token_ids[2]\n",
        "            # But we don't actually want this because number_token_ids[2] could be something like 27, which is now undefined in the new lm_head. So we map it to the new lm_head index.\n",
        "            # if this line gives you a keyerror then increase max_seq_length\n",
        "            batch[\"labels\"][i, last_token_idx] = reverse_map[ batch[\"labels\"][i, last_token_idx].item() ]\n",
        "\n",
        "\n",
        "        return batch\n",
        "collator = DataCollatorForLastTokenLM(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77,
          "referenced_widgets": [
            "72bda92a60df4b8a8ad533f2535c5d12",
            "12fcc1d9e6dc4a579658fd3bedb9c9a8",
            "bd974b7f3dbe4346827abd3df73a5603",
            "3b333a3185254de79f8738c6d14cc7d6",
            "01b16c774d224e818943beba583644f2",
            "0ef81e7c17e144a5a6a84a0a227dee57",
            "fedae276cce14c0b848dbc9443b54223",
            "ae0b788130ea46b6ae035be85928ed98",
            "e1147149965f49aaa90273a23e454bcf",
            "4d202f40a51944789d28cded2d62ed82",
            "5715b8f7e17e4d09b5bb26c8022d8e05"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "27f637a4-4217-4024-feed-0dd6b09dbce8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/8116 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72bda92a60df4b8a8ad533f2535c5d12"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_dataset,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 1,\n",
        "    packing = False, # not needed because group_by_length is True\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 32,\n",
        "        gradient_accumulation_steps = 1,\n",
        "        warmup_steps = 10,\n",
        "        learning_rate = 1e-4,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"cosine\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        num_train_epochs = 1,\n",
        "        # report_to = \"wandb\",\n",
        "        report_to = \"none\",\n",
        "        group_by_length = True,\n",
        "    ),\n",
        "    data_collator=collator,\n",
        "    dataset_text_field=\"text\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "e4370696-5a2b-4dc4-9a54-baa500c232a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "7.775 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "0e9a075c-cfb8-4a3f-e008-760553892f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 8,116 | Num Epochs = 1 | Total steps = 254\n",
            "O^O/ \\_/ \\    Batch size per device = 32 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (32 x 1 x 1) = 32\n",
            " \"-____-\"     Trainable parameters = 33,037,824 of 4,055,513,600 (0.81% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [254/254 20:06, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.782500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.716200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.931500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.795600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.776100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.647900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.575400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.872800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.647300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.701100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.582600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.591200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.777600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.500300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.537100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.608200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.462500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.606800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.495600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.429900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.258100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.572500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.203400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.575200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.203500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.325600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.424000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.810800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.415800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.898900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.100100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.226000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.186800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.175500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.830800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.617900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.467300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.454500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.366100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.346700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.201900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.334400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>2.751300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.903500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.355900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.320000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.614400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.988100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.092000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.161800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.894800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.671500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.034300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.376800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.419200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.341400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.508200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.379000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.590100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.220500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.370100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.412600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.284400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.229000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.337300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.293700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.377100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.315600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.167300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.283100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.583600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.224500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.542000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.259400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.539400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.588400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.364100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.512200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.196700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.322400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.248500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.157100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.201900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.337600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.214000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.088200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.191500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.270900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.241200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.321700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.040900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.368700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.225300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.334700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.682300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.026100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.128100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.012000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.053900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>0.530200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.758300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.304300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>0.361200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.257300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>0.212200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>0.062000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>0.353700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>0.179500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.309800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.229200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>0.138500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>0.164500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.437400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.470300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>0.167300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.326400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>0.106700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>0.202400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.148400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>0.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>0.062000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>0.199100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>0.179600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.206800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>0.252800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>0.189200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>0.166600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>0.449300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.748900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>0.050300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>0.478100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>0.212500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>0.072900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.074800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>0.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>0.028600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>0.051900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>0.145600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.368000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>0.029500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>0.209700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.413600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.228500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>0.326000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>0.029300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>0.011300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>0.014700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.015400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>0.228600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>1.014700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>1.168900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>0.594900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.351600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>0.493800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>0.266900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>0.857300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>0.201900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.334900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>0.133500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>0.135700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>0.169600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>0.130500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.125100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>0.119700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>0.045700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>0.216800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>0.173800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.120300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>0.030300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>0.352000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>0.226900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>0.069700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.073400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>0.035900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>0.240600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>0.102900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>0.018100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.016900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>0.125300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>0.055100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>0.015800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>0.079400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>0.076600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>0.333500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.525700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>0.084400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.033200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>0.120500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>0.106800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.109200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>0.094700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>0.163200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>0.237200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>0.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>0.179400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.012800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>0.059000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>0.018900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>0.280500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>0.288200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.428600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>211</td>\n",
              "      <td>0.054600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>212</td>\n",
              "      <td>0.211400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>214</td>\n",
              "      <td>0.060900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.007300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>0.074400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>218</td>\n",
              "      <td>0.077200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>0.078200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.059000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>0.363700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>223</td>\n",
              "      <td>0.009700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>0.143900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.171200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>226</td>\n",
              "      <td>0.095900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>227</td>\n",
              "      <td>0.052600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>0.132700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>229</td>\n",
              "      <td>0.067800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.041900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>233</td>\n",
              "      <td>0.042900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.024200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>236</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>0.011000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>0.014200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>239</td>\n",
              "      <td>0.039900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.011700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>241</td>\n",
              "      <td>0.140200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>242</td>\n",
              "      <td>0.143900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>0.063200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>244</td>\n",
              "      <td>0.023900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.020900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>0.032400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>247</td>\n",
              "      <td>0.034900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>248</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>251</td>\n",
              "      <td>0.093200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>252</td>\n",
              "      <td>0.030800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>253</td>\n",
              "      <td>0.067700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>254</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqnaKmlO1U9",
        "outputId": "17d682bb-e9db-4b07-d841-07994007f278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1233.3336 seconds used for training.\n",
            "20.56 minutes used for training.\n",
            "Peak reserved memory = 11.168 GB.\n",
            "Peak reserved memory for training = 3.393 GB.\n",
            "Peak reserved memory % of max memory = 75.761 %.\n",
            "Peak reserved memory for training % of max memory = 23.017 %.\n"
          ]
        }
      ],
      "source": [
        "#@title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "This part evaluates the model on the val set with batched inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mwYU4bKiKgY_",
        "outputId": "dd1cd378-8850-4549-c561-c706f17ba0c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNrTcPFmKgZA"
      },
      "source": [
        "### remake the old lm_head but with unused tokens having -1000 bias and 0 weights (improves compatibility with libraries like vllm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "T_ac-ridKgZB",
        "outputId": "414193b7-c8e1-45e9-e950-9df25020daf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remade lm_head: shape = torch.Size([151936, 2560]). Allowed tokens: [15, 16, 17]\n"
          ]
        }
      ],
      "source": [
        "# Save the current (trimmed) lm_head and bias\n",
        "trimmed_lm_head = model.lm_head.weight.data.clone()\n",
        "trimmed_lm_head_bias = model.lm_head.bias.data.clone() if hasattr(model.lm_head, \"bias\") and model.lm_head.bias is not None else torch.zeros(len(number_token_ids), device=trimmed_lm_head.device)\n",
        "\n",
        "# Create a new lm_head with shape [old_size, hidden_dim]\n",
        "hidden_dim = trimmed_lm_head.shape[1]\n",
        "new_lm_head = torch.full((old_size, hidden_dim), 0, dtype=trimmed_lm_head.dtype, device=trimmed_lm_head.device)\n",
        "new_lm_head_bias = torch.full((old_size,), -1000.0, dtype=trimmed_lm_head_bias.dtype, device=trimmed_lm_head_bias.device)\n",
        "\n",
        "# Fill in the weights and bias for the allowed tokens (number_token_ids)\n",
        "for new_idx, orig_token_id in enumerate(number_token_ids):\n",
        "    new_lm_head[orig_token_id] = trimmed_lm_head[new_idx]\n",
        "    new_lm_head_bias[orig_token_id] = trimmed_lm_head_bias[new_idx]\n",
        "\n",
        "# Update the model's lm_head weight and bias\n",
        "with torch.no_grad():\n",
        "    new_lm_head_module = torch.nn.Linear(hidden_dim, old_size, bias=True, device=model.device)\n",
        "    new_lm_head_module.weight.data.copy_(new_lm_head)\n",
        "    new_lm_head_module.bias.data.copy_(new_lm_head_bias)\n",
        "    model.lm_head.modules_to_save[\"default\"] = new_lm_head_module\n",
        "\n",
        "print(f\"Remade lm_head: shape = {model.lm_head.weight.shape}. Allowed tokens: {number_token_ids}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnC_Z0t0KgZC"
      },
      "source": [
        "# Batched Inference on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5zVCulqKgZC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# Prepare inference prompt\n",
        "inference_prompt_template = prompt.split(\"class {}\")[0] + \"class \"\n",
        "\n",
        "# Sort validation set by length for efficient batching\n",
        "val_df['token_length'] = val_df['comment'].apply(lambda x: len(tokenizer.encode(x, add_special_tokens=False)))\n",
        "val_df_sorted = val_df.sort_values(by='token_length').reset_index(drop=True)\n",
        "\n",
        "display = 50\n",
        "batch_size = 2\n",
        "device = model.device\n",
        "correct = 0\n",
        "results = []\n",
        "\n",
        "with torch.inference_mode():\n",
        "    for i in tqdm(range(0, len(val_df_sorted), batch_size), desc=\"Evaluating\"):\n",
        "        batch = val_df_sorted.iloc[i:i+batch_size]\n",
        "        prompts = [\n",
        "            inference_prompt_template.format(comment, rule)\n",
        "            for comment, rule in zip(batch['comment'], batch['rule'])\n",
        "        ]\n",
        "        inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_seq_length).to(device)\n",
        "        logits = model(**inputs).logits\n",
        "        last_idxs = inputs.attention_mask.sum(1) - 1\n",
        "        last_logits = logits[torch.arange(len(batch)), last_idxs, :]\n",
        "        probs_all = F.softmax(last_logits, dim=-1)\n",
        "        probs = probs_all[:, number_token_ids] # only keep the logits for the number tokens\n",
        "        preds = torch.argmax(probs, dim=-1).cpu().numpy() # looks like [1 1 1 1 3 1 3 1 3 1 1 1 1 2 2 3]\n",
        "\n",
        "        true_labels = batch['label'].tolist()\n",
        "        correct += sum([p == t for p, t in zip(preds, true_labels)])\n",
        "        # Store a few samples for display\n",
        "        for j in range(len(batch)):\n",
        "            results.append({\n",
        "                \"text\": batch['comment'].iloc[j][:200],\n",
        "                \"true\": true_labels[j],\n",
        "                \"pred\": preds[j],\n",
        "                \"probs\": probs[j][1:].float().cpu().numpy(), # ignore prob for class 0 and convert from tensor to float\n",
        "                \"ok\": preds[j] == true_labels[j]\n",
        "            })\n",
        "\n",
        "accuracy = 100 * correct / len(val_df_sorted)\n",
        "print(f\"\\nValidation accuracy: {accuracy:.2f}% ({correct}/{len(val_df_sorted)})\")\n",
        "\n",
        "print(\"\\n--- Random samples ---\")\n",
        "for s in random.sample(results, min(display, len(results))):\n",
        "    print(f\"\\nText: {s['text']}\")\n",
        "    print(f\"True: {s['true']}  Pred: {s['pred']} {'âœ…' if s['ok'] else 'âŒ'}\")\n",
        "    print(\"Probs:\", \", \".join([f\"{k}: {v:.3f}\" for k, v in enumerate(s['probs'], start=1)]))\n",
        "\n",
        "# Clean up\n",
        "if 'token_length' in val_df:\n",
        "    del val_df['token_length']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 100 * correct / len(val_df_sorted)\n",
        "print(f\"\\nValidation accuracy: {accuracy:.2f}% ({correct}/{len(val_df_sorted)})\")\n",
        "\n",
        "print(\"\\n--- Random samples ---\")\n",
        "for s in random.sample(results, min(display, len(results))):\n",
        "    print(f\"\\nText: {s['text']}\")\n",
        "    print(f\"True: {s['true']}  Pred: {s['pred']} {'âœ…' if s['ok'] else 'âŒ'}\")\n",
        "    print(\"Probs:\", \", \".join([f\"{k}: {v:.3f}\" for k, v in enumerate(s['probs'], start=1)]))\n",
        "\n",
        "# Clean up\n",
        "if 'token_length' in val_df:\n",
        "    del val_df['token_length']"
      ],
      "metadata": {
        "id": "aiACenqrbt4K",
        "outputId": "6ccdfa91-cbdd-422d-f274-b5121b7b3016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation accuracy: 81.07% (1645/2029)\n",
            "\n",
            "--- Random samples ---\n",
            "\n",
            "Text: You should also consider the fact that if anybody from the IRS is reading this they may well become involved. If you use a loan as income the IRS will tax it as such.\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.547, 2: 0.000\n",
            "\n",
            "Text: Don't forget peeing in public.  Or being seen by a child while you skinnydip in your pool.  Those kinds of things can and have landed people on sex offender registries.\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.015, 2: 0.000\n",
            "\n",
            "Text: Except he wasn't a thug. Thug literally means \"violent person, usually a criminal.\" This kid wasn't being violent at all and not really a criminal,  either. He didn't cross over to being technically a\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.827, 2: 0.000\n",
            "\n",
            "Text: We're streaming Pokemon Veitnamese Crystal RIGHT NOW, come watch https://www.twitch.tv/adandyguyinspace55.\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.003, 2: 0.000\n",
            "\n",
            "Text: Here it is: https://eroshare.com/rmkx43df\n",
            "\n",
            "http://www.pornhub.com/view_video.php?viewkey=208297627\n",
            "\n",
            "More of Natalie Moore: \n",
            "\n",
            "http://www.pornhub.com/view_video.php?viewkey=1929996095\n",
            "\n",
            "http://www.pornhu\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.985, 2: 0.000\n",
            "\n",
            "Text: link to pictures on supload and earn bitcoin.\n",
            "\n",
            "https://supload.com/H1EAxlLHx\n",
            "\n",
            "Gifs too: https://supload.com/SJboBnEBe\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.703, 2: 0.000\n",
            "\n",
            "Text: I'm an asshole. Obtain handcuffs or duct tape. The next time they hit you, give them a warning that they won't be able to use their hands if they hit you again. If they hit you again, handcuff their h\n",
            "True: 1  Pred: 0 âŒ\n",
            "Probs: 1: 0.055, 2: 0.000\n",
            "\n",
            "Text: If it's *only* killing sick, elderly people - isn't it kind of... alright?\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.000, 2: 0.000\n",
            "\n",
            "Text:  see  there  hooters  sweet  http://url.t.aylor.de/2176b\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 1.000, 2: 0.000\n",
            "\n",
            "Text: Can you beat and rape her? Then get her pregnant and blame her afterwards? I mean it was her fault she was asking for it by being in the same room as me.\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.015, 2: 0.000\n",
            "\n",
            "Text: You know this isn't the first time he's been sued over Trump U, right?  He has won all previous frivolous lawsuits and he will win this one, too.  He wins because they are nonsense.\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.999, 2: 0.000\n",
            "\n",
            "Text: Beachworld.\n",
            "\n",
            "Good short story with a surprisingly big universe sketched out with little details.\n",
            "\n",
            "And here 'tis: http://www.experienceproject.com/stories/Feasibilitystudys-Collection-Of-Speculative-Fi\n",
            "True: 1  Pred: 0 âŒ\n",
            "Probs: 1: 0.004, 2: 0.000\n",
            "\n",
            "Text: Don't do it. I spent 3 hours soloing the Nightfall and I got 17 strange coins. Oh by the way, unrelated question, what's the most painless way to kill yourself?\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.006, 2: 0.000\n",
            "\n",
            "Text: [[Staci Carr - You're my desire|http://www.sextvx.com/en/video/702613/staci-carr-youre-my-desire-20-feb]]\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.850, 2: 0.000\n",
            "\n",
            "Text: so they can call the men rapist and charge them with fines.\n",
            "\n",
            "remember assange? he is rapist too, for not using a condom cause it broke in the middle\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.000, 2: 0.000\n",
            "\n",
            "Text: >I've just plain stopped letting my Windows 7 machine update.\n",
            "\n",
            "Please click the following link for me.\n",
            "\n",
            "http://NoImNotAVirusThatWillAutoExecuteInIE.WhenYouClickThisInUnPatchedWindows.com/NotAn.EXE.vbs\n",
            "True: 1  Pred: 0 âŒ\n",
            "Probs: 1: 0.137, 2: 0.000\n",
            "\n",
            "Text: Depends how much you want to keep your liquor license.  \n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.007, 2: 0.000\n",
            "\n",
            "Text: Doesn't the NYC law also prohibit discrimination based on age?  Doesn't that mean \"adult only\" swim times are also illegal in NYC?\n",
            "True: 1  Pred: 0 âŒ\n",
            "Probs: 1: 0.488, 2: 0.000\n",
            "\n",
            "Text: Liverpool vs West Bromwich Albion: [HD/English/No Lags - Stream!](http://www.melbournecuplivestreaming.com/)\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.000, 2: 0.000\n",
            "\n",
            "Text:  herein  you  looking for  sexy  tits  http://cumto.loan/?id34526\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 1.000, 2: 0.000\n",
            "\n",
            "Text: Hello. What can I offer. Here are links to my trade shop:\n",
            "LF: http://poketrade.us/shop/9960/lf FT: http://poketrade.us/shop/9960/ft\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.876, 2: 0.000\n",
            "\n",
            "Text: This is serious felony territory for your parents. If you're on good terms with your parents, time to see about unwinding this and get the stuff transferred out of your name. If on bad terms, you can \n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 1.000, 2: 0.000\n",
            "\n",
            "Text: Yes it's legal for you to choose to share them, no, she may not demand any information about your child's health from you.\n",
            "True: 1  Pred: 0 âŒ\n",
            "Probs: 1: 0.442, 2: 0.000\n",
            "\n",
            "Text: You can fund a Better Answer there \n",
            "http://xbox3711.blogspot.com\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.034, 2: 0.000\n",
            "\n",
            "Text: State dependant. There are states where it's perfectly legal to shoot to kill a thief escaping on your bike.\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.554, 2: 0.000\n",
            "\n",
            "Text: Because I love you all\n",
            "http://hdporn720.net/cassidy-klein-teens-love-huge-cocks-12/\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.991, 2: 0.000\n",
            "\n",
            "Text: This is going to be interesting.\n",
            "\n",
            "http://www.nigerianews360.com/\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.009, 2: 0.000\n",
            "\n",
            "Text: Get it while it's HOT ! Get 25k bonus Starpoints after $3k spend in first 3 months. Annual Fee waived first year! Thanks! :)\n",
            "\n",
            "https://www.americanexpress.com/us/credit-cards/personal-card-application/\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.604, 2: 0.000\n",
            "\n",
            "Text: No idea about NY, but in Texas it is not technically a crime, nor would it meet the definitions of trespass to chattel in Texas because you have no real damages.\n",
            "\n",
            "Maybe, by a big stretch, it could be \n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.994, 2: 0.000\n",
            "\n",
            "Text: Probably walk around on the boardwalk, search for the smell of weed, ask someone if they're selling. You could also look for people who look like they smoke (the white guy with dreadlocks smokes a lot\n",
            "True: 1  Pred: 0 âŒ\n",
            "Probs: 1: 0.025, 2: 0.000\n",
            "\n",
            "Text: That isn't drastic. You tried reaching out to her directly. She avoided your calls/texts, and HUNG UP ON YOU as soon as she realized it was your voice on her work line.  \n",
            "\n",
            "Bitch stole your puppy - a p\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.608, 2: 0.000\n",
            "\n",
            "Text: Da fuck?  No, in this case, this particular spate of killings is motivated by dissimilar cultures rejecting one another, and that's not my fault.  I had literally nothing to do with any of this, I'm j\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.099, 2: 0.000\n",
            "\n",
            "Text: They dind't intend to, so we recommend no indictment.\n",
            "\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.217, 2: 0.000\n",
            "\n",
            "Text: If you do not want to waste a single penny in knowing the biographies of the famous celebrities, you can know it from the wiki. You just need an Internet connection. A lot of information is provided a\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.780, 2: 0.000\n",
            "\n",
            "Text: Tell her you will sue her for $1,000,000,000 and her first born on Judge Judy in Canada if she doesn't stop contacting you.  That ought to show her how serious these threats are.\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.562, 2: 0.000\n",
            "\n",
            "Text: That is called battery.  Two wrongs don't make a right.\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.015, 2: 0.000\n",
            "\n",
            "Text: Withdraw it FAST and spend it all on various goods and services that you enjoy!  Its your money if its in your name.\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.142, 2: 0.000\n",
            "\n",
            "Text: [Ø³Ø§Ø®Øª ÙˆØ¨Ù„Ø§Ú¯](http://parsablog.com)\n",
            "\n",
            "http://parsablog.com\n",
            "\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.012, 2: 0.000\n",
            "\n",
            "Text: another travesty, underrated players \n",
            "\n",
            "http://statstuffers.com/content/nba-all-underrated-team\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.002, 2: 0.000\n",
            "\n",
            "Text: Guys, my wife's boyfriend told me that the recount effort (which we donated to) has pretty much fallen through. Is there any way Jill can bring this up to the supreme court while it's still majority d\n",
            "True: 1  Pred: 0 âŒ\n",
            "Probs: 1: 0.345, 2: 0.000\n",
            "\n",
            "Text: >[ufc 202 ppv](http://nbamania.online/ufc) live here\n",
            "\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.005, 2: 0.000\n",
            "\n",
            "Text: The problem is that you don't understand the legal definition of murder. \n",
            "\n",
            "Kill =/= murder.\n",
            "\n",
            "Do you think the cop that shot the black man pointing the vape like a gun should be fired for killing an un\n",
            "True: 0  Pred: 1 âŒ\n",
            "Probs: 1: 0.988, 2: 0.000\n",
            "\n",
            "Text: Hello misandry, it was a false rape accusation, watch the video on pornhub, she was enjoying herself.\n",
            "\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.098, 2: 0.000\n",
            "\n",
            "Text: Don't know about your situation, but in my country that person would have had to pay for their knee surgery as well after gross neglect like that, if you know what I mean.\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.030, 2: 0.000\n",
            "\n",
            "Text: Aw!! It's just a little murder. Surely we can overlook that.\n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.000, 2: 0.000\n",
            "\n",
            "Text: Actually this is 90% not a heart problem, but probably something with elevated nerve system. Symptoms are scary as shit for common person, everybody thinks something bad is with him, but its not life \n",
            "True: 0  Pred: 0 âœ…\n",
            "Probs: 1: 0.004, 2: 0.000\n",
            "\n",
            "Text: > I just found out that his girlfriend called my family more than once since the affair crying because my brother hit her. He has never been violent before. He's also been smoking pot every day and dr\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.998, 2: 0.000\n",
            "\n",
            "Text: 42 http://MySexFind.com - find girl for sex now 42!\n",
            "True: 1  Pred: 1 âœ…\n",
            "Probs: 1: 0.939, 2: 0.000\n",
            "\n",
            "Text: unethical but... make a SS# but state name and address and all perfectly.  If the IRS asks, just say that's the number you got, let the IRS sort if out for you.\n",
            "True: 1  Pred: 0 âŒ\n",
            "Probs: 1: 0.385, 2: 0.000\n",
            "\n",
            "Text: > distance\n",
            "\n",
            "[Working Genuine Trick To Hatch Your Eggs  Faster]\n",
            "For All Pokemon GO Lovers!\n",
            "\n",
            "This is crazy Pokemon Go trick! How to get unlimited walking distance without actually walking! Sitting at ho\n",
            "True: 1  Pred: 0 âŒ\n",
            "Probs: 1: 0.004, 2: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHmRsnm_KgZD",
        "outputId": "bd0a74cf-af68-4185-ec08-63daff793b70"
      },
      "outputs": [
        {
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# stop running all cells\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
            "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "source": [
        "# stop running all cells\n",
        "1/0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0pCfYnaKgZE"
      },
      "source": [
        "Now if you closed the notebook kernel and want to reload the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwczAiRqKgZE",
        "outputId": "cd22c9a3-19a9-4616-9b72-489fa405aea5",
        "colab": {
          "referenced_widgets": [
            "73992b1f949448ce9981a732af2d7b66"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:330: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
            "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"cuda:{i}\") for i in range(n_gpus)])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.4.5: Fast Qwen3 patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 1. Max memory: 23.999 GB. Platform: Windows.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73992b1f949448ce9981a732af2d7b66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.4.5 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully.\n",
            "[\"Here is a financial news:\\nFor the global oil market, the coronavirus epidemic couldn't have hit a worse place\\n\\nClassify this news into one of the following:\\nclass 1: Bullish\\nclass 2: Neutral\\nclass 3: Bearish\\n\\nSOLUTION\\nThe correct answer is: class 3\"]\n"
          ]
        }
      ],
      "source": [
        "# load the model\n",
        "from unsloth import FastLanguageModel\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"lora_model_Qwen3-4B-Base\",\n",
        "    load_in_4bit = False,\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        ")\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "prompt = \"\"\"Here is a financial news:\n",
        "For the global oil market, the coronavirus epidemic couldn't have hit a worse place\n",
        "\n",
        "Classify this news into one of the following:\n",
        "class 1: Bullish\n",
        "class 2: Neutral\n",
        "class 3: Bearish\n",
        "\n",
        "SOLUTION\n",
        "The correct answer is: class \"\"\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "outputs = model.generate(**inputs, max_new_tokens=1, use_cache=True)\n",
        "decoded = tokenizer.batch_decode(outputs)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDp0zNpwe6U_"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in `llama.cpp` or a UI based system like `GPT4All`. You can install GPT4All by going [here](https://gpt4all.io/index.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt9CHJqO6p30"
      },
      "source": [
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/u54VK8m8tk) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Zephyr DPO 2x faster [free Colab](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)\n",
        "2. Llama 7b 2x faster [free Colab](https://colab.research.google.com/drive/1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5?usp=sharing)\n",
        "3. TinyLlama 4x faster full Alpaca 52K in 1 hour [free Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)\n",
        "4. CodeLlama 34b 2x faster [A100 on Colab](https://colab.research.google.com/drive/1y7A0AxE3y8gdj4AVkl2aZX47Xu3P1wJT?usp=sharing)\n",
        "5. Llama 7b [free Kaggle](https://www.kaggle.com/danielhanchen/unsloth-alpaca-t4-ddp)\n",
        "6. We also did a [blog](https://huggingface.co/blog/unsloth-trl) with ğŸ¤— HuggingFace, and we're in the TRL [docs](https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Support our work if you can! Thanks!\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5081962,
          "sourceId": 8512897,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f8336b274cc24d7fbfedaa0f841f83cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4cbee7ae6e54774b223f83bb7e4639d",
              "IPY_MODEL_4bf6ffb1559c4765ae7add3d4254c2ba",
              "IPY_MODEL_9f67a2eb09e14218ac05251527f5a94e"
            ],
            "layout": "IPY_MODEL_aeaa825fabdb4788ae06e0c3756e2224"
          }
        },
        "e4cbee7ae6e54774b223f83bb7e4639d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fc326fbd2b348c8be49ceca07124c1e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ce8d6fd57aef4ece83eaeb9b5c0ee0ab",
            "value": "model.safetensors.index.json:â€‡"
          }
        },
        "4bf6ffb1559c4765ae7add3d4254c2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_291fc04ec56d4085ab0ede398aad21b1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a06430ef7ad141b48ef923a410bc0b46",
            "value": 1
          }
        },
        "9f67a2eb09e14218ac05251527f5a94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_443eab1dba2642d79f9cf003efcb1800",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bbb4176350bf4325b8c84bb919913653",
            "value": "â€‡32.8k/?â€‡[00:00&lt;00:00,â€‡3.27MB/s]"
          }
        },
        "aeaa825fabdb4788ae06e0c3756e2224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fc326fbd2b348c8be49ceca07124c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce8d6fd57aef4ece83eaeb9b5c0ee0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "291fc04ec56d4085ab0ede398aad21b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a06430ef7ad141b48ef923a410bc0b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "443eab1dba2642d79f9cf003efcb1800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbb4176350bf4325b8c84bb919913653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36e8f92172fb4da1b5c39872d9967d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e03eadf2a26449c5bfb662ab22221adf",
              "IPY_MODEL_382767c88dad4b93abb20406f5cb3513",
              "IPY_MODEL_37cb19d891ef46409704c7ea7797d462"
            ],
            "layout": "IPY_MODEL_a2135168f99845f486c5170aa6bdb3e2"
          }
        },
        "e03eadf2a26449c5bfb662ab22221adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0efd46fac188423ba286ec292266aee3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6ff963ac45be49ae82611bca330c527a",
            "value": "model-00001-of-00002.safetensors:â€‡100%"
          }
        },
        "382767c88dad4b93abb20406f5cb3513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f06465261f9c462ba40545effffd15ba",
            "max": 4967215360,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_654adb65cf0f437c822797ebd9a274c1",
            "value": 4967215360
          }
        },
        "37cb19d891ef46409704c7ea7797d462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99ebf1e4b90c498d804b7aaf293bd2c5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4498d891ea774062bd9ee7dea0b09402",
            "value": "â€‡4.97G/4.97Gâ€‡[00:47&lt;00:00,â€‡110MB/s]"
          }
        },
        "a2135168f99845f486c5170aa6bdb3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0efd46fac188423ba286ec292266aee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff963ac45be49ae82611bca330c527a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f06465261f9c462ba40545effffd15ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "654adb65cf0f437c822797ebd9a274c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99ebf1e4b90c498d804b7aaf293bd2c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4498d891ea774062bd9ee7dea0b09402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "668d76b8341d4f26af3f6c9885d00c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d110dca213704c26af707e0c085f01a9",
              "IPY_MODEL_75b93b8951d34bb4b2aee3565b9331ab",
              "IPY_MODEL_d65f695bc30d4d3d900ff9df152a82a6"
            ],
            "layout": "IPY_MODEL_a6c90c4f3a5c43d5a6e71e7904578cc5"
          }
        },
        "d110dca213704c26af707e0c085f01a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f576539d1b9746c0bef3cd98154bc54a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c82f5d962d2c46dfb275d34e81ec4bf9",
            "value": "model-00002-of-00002.safetensors:â€‡â€‡96%"
          }
        },
        "75b93b8951d34bb4b2aee3565b9331ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a17b50f2594bf9b5689e8d19286275",
            "max": 3077766632,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3c4c3d3a2ee4c2f982dd32bf94d7164",
            "value": 2950771304
          }
        },
        "d65f695bc30d4d3d900ff9df152a82a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_411747a1dc84446986a8603dfc3c06aa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_25797b68da6342cd8723270ce8ac2f92",
            "value": "â€‡2.95G/3.08Gâ€‡[00:53&lt;00:01,â€‡72.9MB/s]"
          }
        },
        "a6c90c4f3a5c43d5a6e71e7904578cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f576539d1b9746c0bef3cd98154bc54a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c82f5d962d2c46dfb275d34e81ec4bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61a17b50f2594bf9b5689e8d19286275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c4c3d3a2ee4c2f982dd32bf94d7164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "411747a1dc84446986a8603dfc3c06aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25797b68da6342cd8723270ce8ac2f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72bda92a60df4b8a8ad533f2535c5d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12fcc1d9e6dc4a579658fd3bedb9c9a8",
              "IPY_MODEL_bd974b7f3dbe4346827abd3df73a5603",
              "IPY_MODEL_3b333a3185254de79f8738c6d14cc7d6"
            ],
            "layout": "IPY_MODEL_01b16c774d224e818943beba583644f2"
          }
        },
        "12fcc1d9e6dc4a579658fd3bedb9c9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ef81e7c17e144a5a6a84a0a227dee57",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fedae276cce14c0b848dbc9443b54223",
            "value": "Unsloth:â€‡Tokenizingâ€‡[&quot;text&quot;]â€‡(num_proc=6):â€‡100%"
          }
        },
        "bd974b7f3dbe4346827abd3df73a5603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae0b788130ea46b6ae035be85928ed98",
            "max": 8116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1147149965f49aaa90273a23e454bcf",
            "value": 8116
          }
        },
        "3b333a3185254de79f8738c6d14cc7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d202f40a51944789d28cded2d62ed82",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5715b8f7e17e4d09b5bb26c8022d8e05",
            "value": "â€‡8116/8116â€‡[00:06&lt;00:00,â€‡3064.22â€‡examples/s]"
          }
        },
        "01b16c774d224e818943beba583644f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef81e7c17e144a5a6a84a0a227dee57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fedae276cce14c0b848dbc9443b54223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae0b788130ea46b6ae035be85928ed98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1147149965f49aaa90273a23e454bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d202f40a51944789d28cded2d62ed82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5715b8f7e17e4d09b5bb26c8022d8e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}